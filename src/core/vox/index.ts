/**
 * VOX - Agent de Liaison Utilisateur
 *
 * NOUVEAU FLUX:
 * 1. Re√ßoit message utilisateur
 * 2. Demande un rapport de contexte √† Memory
 * 3. R√©√©crit le prompt avec le contexte Memory
 * 4. Envoie le prompt enrichi √† Brain
 * 5. Re√ßoit la r√©ponse et la formate pour l'utilisateur
 * 6. Envoie l'√©change complet √† Memory pour stockage
 *
 * Responsabilit√©s :
 * - Interface entre l'utilisateur et le syst√®me
 * - Enrichissement des prompts avec contexte Memory
 * - Pr√©sentation des r√©ponses du syst√®me
 * - Gestion du ton et du style de communication
 * - D√©tection d'intentions et d'√©motions
 */

import { BaseAgent } from '../base-agent';
import type { AgentConfig, AgentMessage, ConversationTurn } from '../types';
import { ContextReport } from '../memory';

// ===========================================================================
// TYPES
// ===========================================================================

interface VoxState {
  conversationHistory: ConversationTurn[];
  currentMood: 'neutral' | 'helpful' | 'clarifying' | 'apologetic';
  pendingResponse: boolean;
  currentSessionId: string;
  lastUserMessage: string | null;
}

interface InputAnalysis {
  intent: string;
  confidence: number;
  needsClarification: boolean;
  clarificationQuestion: string | null;
  processedInput: string;
  suggestedPriority: number;
  emotionalTone: string;
}

// ===========================================================================
// PROMPTS
// ===========================================================================

const VOX_SYSTEM_PROMPT = `Tu es VOX, l'interface vocale et textuelle d'un syst√®me d'IA avanc√©.

TON R√îLE :
- Tu es le point de contact unique avec l'utilisateur
- Tu re√ßois ses messages et les enrichis avec le contexte de la m√©moire
- Tu pr√©sentes les r√©ponses de mani√®re claire et adapt√©e
- Tu ne mens JAMAIS - si tu ne sais pas, tu le dis

STYLE DE COMMUNICATION :
- Naturel et conversationnel
- Concis mais complet
- Adapte-toi au style de l'utilisateur
- Utilise un ton professionnel mais chaleureux

R√àGLES :
1. Ne jamais inventer d'information
2. Toujours indiquer le niveau de confiance si pertinent
3. Demander des clarifications UNIQUEMENT si la demande est vraiment ambigu√´
4. Reconna√Ætre les erreurs imm√©diatement
5. IMPORTANT: Si l'utilisateur demande de "tester", "v√©rifier", "ex√©cuter" ‚Üí c'est une COMMANDE, pas besoin de clarifier
6. Privil√©gier l'ACTION sur la clarification - en cas de doute, agir plut√¥t que demander

MOTS-CL√âS D'ACTION (ne pas demander de clarification):
- "teste", "test", "v√©rifier", "v√©rifie", "check"
- "ex√©cute", "lance", "fais", "run"
- "montre", "affiche", "liste"

FORMAT DE SORTIE POUR ANALYSE :
Tu dois TOUJOURS r√©pondre en JSON avec cette structure :
{
  "intent": "question|command|feedback|clarification|greeting|other",
  "confidence": 0.0-1.0,
  "needsClarification": boolean,
  "clarificationQuestion": "string ou null",
  "processedInput": "version normalis√©e de l'entr√©e utilisateur",
  "suggestedPriority": 1-10,
  "emotionalTone": "neutral|positive|negative|frustrated|confused"
}

IMPORTANT: Pour les commandes (test, v√©rifie, ex√©cute...), needsClarification doit √™tre FALSE.`;

const PROMPT_REWRITE_TEMPLATE = `Tu dois r√©√©crire ce prompt utilisateur en l'enrichissant avec le contexte fourni par la m√©moire ET l'historique de conversation.

PROMPT ORIGINAL: "{originalInput}"

HISTORIQUE DE CONVERSATION R√âCENT:
{conversationHistory}

CONTEXTE M√âMOIRE:
{contextSummary}

FAITS PERTINENTS:
{relevantFacts}

PR√âF√âRENCES UTILISATEUR:
{userPreferences}

AVERTISSEMENTS:
{warnings}

APPRENTISSAGES R√âCENTS:
{learnings}

---

R√àGLES IMPORTANTES:
1. L'historique de conversation est CRITIQUE - il contient le contexte imm√©diat
2. Si l'utilisateur fait r√©f√©rence √† quelque chose dit pr√©c√©demment ("alors ?", "et √ßa ?", "comme je disais"), utilise l'historique pour comprendre
3. Ne perds JAMAIS le fil de la conversation

R√©√©cris le prompt en:
1. Gardant l'intention originale de l'utilisateur
2. INT√âGRANT le contexte de la conversation r√©cente si pertinent
3. Ajoutant le contexte m√©moire pertinent
4. Mentionnant les pr√©f√©rences si applicable
5. Signalant les points d'attention

R√©ponds en JSON:
{
  "enrichedPrompt": "Le prompt r√©√©crit avec contexte de conversation et m√©moire",
  "contextUsed": ["liste des √©l√©ments de contexte utilis√©s"],
  "warnings": ["avertissements √† transmettre √† Brain"]
}`;

// ===========================================================================
// VOX AGENT
// ===========================================================================

export class VoxAgent extends BaseAgent {
  private state: VoxState;
  private pendingContextRequests: Map<string, (report: ContextReport) => void> = new Map();
  private isProcessingMessage = false; // Circuit breaker pour √©viter r√©cursion

  constructor(config?: Partial<AgentConfig>) {
    super({
      name: 'Vox',
      role: 'vox',
      model: 'claude-haiku-4-5-20251001', // Haiku 4.5 pour l'interface
      maxTokens: 1024,
      temperature: 0.3,
      systemPrompt: VOX_SYSTEM_PROMPT,
      ...config,
    });

    this.state = {
      conversationHistory: [],
      currentMood: 'neutral',
      pendingResponse: false,
      currentSessionId: this.generateSessionId(),
      lastUserMessage: null,
    };
  }

  private generateSessionId(): string {
    return `session_${Date.now()}_${Math.random().toString(36).substring(7)}`;
  }

  // ===========================================================================
  // POINT D'ENTR√âE PRINCIPAL
  // ===========================================================================

  /**
   * Point d'entr√©e principal : recevoir un message utilisateur
   * NOUVEAU FLUX: Demande d'abord le contexte √† Memory
   */
  async receiveUserInput(input: string): Promise<void> {
    console.log(`[Vox] üì• Entr√©e utilisateur: "${input.substring(0, 50)}..."`);

    this.state.lastUserMessage = input;

    // Ajouter √† l'historique
    this.state.conversationHistory.push({
      role: 'user',
      content: input,
      timestamp: new Date(),
    });

    try {
      // 1. Analyser l'entr√©e basiquement
      const analysis = await this.analyzeInput(input);

      // Si clarification n√©cessaire, demander directement
      if (analysis.needsClarification && analysis.clarificationQuestion) {
        this.emitToUser(analysis.clarificationQuestion);
        return;
      }

      // 2. Demander le rapport de contexte √† Memory
      console.log('[Vox] üìã Demande de contexte √† Memory...');
      const contextReport = await this.requestContextReport(input);

      // 3. R√©√©crire le prompt avec le contexte
      console.log('[Vox] ‚úçÔ∏è R√©√©criture du prompt avec contexte...');
      const enrichedPrompt = await this.rewritePromptWithContext(input, contextReport);

      // 4. Envoyer au Brain
      this.state.pendingResponse = true;
      this.send('brain', 'user_input', {
        originalInput: input,
        enrichedInput: enrichedPrompt.enrichedPrompt,
        analysis,
        contextReport: {
          confidence: contextReport.confidence,
          warnings: [...contextReport.warnings, ...enrichedPrompt.warnings],
          contextUsed: enrichedPrompt.contextUsed,
        },
        conversationContext: this.getRecentContext(),
      });
    } catch (error) {
      console.error('[Vox] Erreur traitement entr√©e:', error);
      this.emitToUser("D√©sol√©, je rencontre un probl√®me technique. V√©rifiez la configuration avec ./neo config");
    }
  }

  // ===========================================================================
  // INTERACTION AVEC MEMORY
  // ===========================================================================

  /**
   * Demander un rapport de contexte √† Memory
   */
  private async requestContextReport(userInput: string): Promise<ContextReport> {
    return new Promise((resolve) => {
      const requestId = `ctx_${Date.now()}`;

      // Stocker le callback pour quand Memory r√©pond
      this.pendingContextRequests.set(requestId, resolve);

      // Timeout si Memory ne r√©pond pas (augment√© √† 10s pour laisser le temps aux embeddings)
      setTimeout(() => {
        if (this.pendingContextRequests.has(requestId)) {
          this.pendingContextRequests.delete(requestId);
          console.log('[Vox] ‚ö†Ô∏è Timeout contexte Memory - utilisation fallback');
          resolve(this.createEmptyContextReport());
        }
      }, 10000);

      // Envoyer la demande √† Memory
      this.send('memory', 'context_report_request', {
        userInput,
        requestId,
      });
    });
  }

  private createEmptyContextReport(): ContextReport {
    return {
      relevantMemories: [],
      userProfile: {
        preferences: {},
        communicationStyle: 'professional',
        knownFacts: [],
      },
      recentLearnings: [],
      suggestedContext: '',
      warnings: [],
      confidence: 0.5,
    };
  }

  // ===========================================================================
  // R√â√âCRITURE DE PROMPT
  // ===========================================================================

  /**
   * Synth√©tiser l'historique de conversation pour √©conomiser des tokens
   * Au lieu d'envoyer tout l'historique, on extrait le sujet actuel
   */
  private synthesizeConversationContext(history: ConversationTurn[]): string {
    if (history.length === 0) return '';
    if (history.length === 1) return history[0].content;

    // Extraire le dernier √©change complet (question + r√©ponse)
    const lastUserMsg = [...history].reverse().find(h => h.role === 'user');
    const lastAssistantMsg = [...history].reverse().find(h => h.role === 'assistant');

    // Construire un r√©sum√© compact
    const parts: string[] = [];

    if (lastUserMsg) {
      // Tronquer si trop long
      const userContent = lastUserMsg.content.length > 200
        ? lastUserMsg.content.substring(0, 200) + '...'
        : lastUserMsg.content;
      parts.push(`Derni√®re demande: "${userContent}"`);
    }

    if (lastAssistantMsg) {
      // R√©sumer la r√©ponse (garder le d√©but)
      const assistantContent = lastAssistantMsg.content.length > 150
        ? lastAssistantMsg.content.substring(0, 150) + '...'
        : lastAssistantMsg.content;
      parts.push(`Derni√®re r√©ponse: "${assistantContent}"`);
    }

    // Ajouter le sujet g√©n√©ral si d√©tectable
    const allUserMessages = history.filter(h => h.role === 'user').map(h => h.content).join(' ');
    const topics = this.detectTopics(allUserMessages);
    if (topics.length > 0) {
      parts.push(`Sujets abord√©s: ${topics.join(', ')}`);
    }

    return parts.join('\n');
  }

  /**
   * D√©tecter les sujets principaux d'une conversation
   */
  private detectTopics(text: string): string[] {
    const topics: string[] = [];
    const lowerText = text.toLowerCase();

    // Patterns de sujets courants
    const topicPatterns: [RegExp, string][] = [
      [/\b(atp|tennis|match|tournoi)\b/i, 'tennis/ATP'],
      [/\b(foot|football|ligue|champion)\b/i, 'football'],
      [/\b(m√©t√©o|temps|pluie|soleil)\b/i, 'm√©t√©o'],
      [/\b(code|bug|erreur|fonction)\b/i, 'programmation'],
      [/\b(test|v√©rif|check)\b/i, 'tests'],
      [/\b(m√©moire|memory|embedding)\b/i, 'syst√®me m√©moire'],
    ];

    for (const [pattern, topic] of topicPatterns) {
      if (pattern.test(lowerText) && !topics.includes(topic)) {
        topics.push(topic);
      }
    }

    return topics.slice(0, 3); // Max 3 sujets
  }

  /**
   * R√©√©crire le prompt utilisateur avec le contexte de Memory ET l'historique de conversation
   */
  private async rewritePromptWithContext(
    originalInput: string,
    contextReport: ContextReport
  ): Promise<{
    enrichedPrompt: string;
    contextUsed: string[];
    warnings: string[];
  }> {
    // R√©cup√©rer et SYNTH√âTISER l'historique (√©conomie de tokens)
    const recentHistory = this.getRecentContext(6);
    const synthesizedHistory = this.synthesizeConversationContext(recentHistory);

    // Si pas de contexte m√©moire mais on a un historique, on enrichit quand m√™me
    const hasMemoryContext = contextReport.relevantMemories.length > 0 ||
      contextReport.suggestedContext ||
      contextReport.recentLearnings.length > 0;

    // Si vraiment rien (pas d'historique et pas de contexte), retourner le prompt original
    if (recentHistory.length <= 1 && !hasMemoryContext) {
      return {
        enrichedPrompt: originalInput,
        contextUsed: [],
        warnings: [],
      };
    }

    try {
      const prompt = PROMPT_REWRITE_TEMPLATE
        .replace('{originalInput}', originalInput)
        .replace('{conversationHistory}', synthesizedHistory || 'Aucun historique')
        .replace('{contextSummary}', contextReport.suggestedContext || 'Aucun contexte sp√©cifique')
        .replace('{relevantFacts}',
          contextReport.userProfile.knownFacts.length > 0
            ? contextReport.userProfile.knownFacts.join('\n- ')
            : 'Aucun fait pertinent'
        )
        .replace('{userPreferences}',
          Object.keys(contextReport.userProfile.preferences).length > 0
            ? JSON.stringify(contextReport.userProfile.preferences, null, 2)
            : 'Aucune pr√©f√©rence connue'
        )
        .replace('{warnings}',
          contextReport.warnings.length > 0
            ? contextReport.warnings.join('\n- ')
            : 'Aucun avertissement'
        )
        .replace('{learnings}',
          contextReport.recentLearnings.length > 0
            ? contextReport.recentLearnings.join('\n- ')
            : 'Aucun apprentissage r√©cent'
        );

      // Utiliser thinkOptimized - la r√©√©criture est une t√¢che simple/factuelle
      const response = await this.thinkOptimized(prompt, 'factual');
      const jsonMatch = response.match(/\{[\s\S]*\}/);

      if (jsonMatch) {
        const parsed = JSON.parse(jsonMatch[0]);
        console.log(`[Vox] ‚úÖ Prompt enrichi avec ${parsed.contextUsed?.length || 0} √©l√©ments de contexte`);
        return {
          enrichedPrompt: parsed.enrichedPrompt || originalInput,
          contextUsed: parsed.contextUsed || [],
          warnings: parsed.warnings || [],
        };
      }
    } catch (error) {
      console.error('[Vox] Erreur r√©√©criture prompt:', error);
    }

    // Fallback: prompt original avec historique de conversation et contexte simple
    let enriched = originalInput;
    const contextUsed: string[] = [];

    // TOUJOURS ajouter l'historique synth√©tis√© en fallback
    if (recentHistory.length > 1 && synthesizedHistory) {
      enriched = `[Contexte conversation: ${synthesizedHistory}]\n\n${originalInput}`;
      contextUsed.push('conversationHistory');
    }

    if (contextReport.suggestedContext) {
      enriched = `[Contexte m√©moire: ${contextReport.suggestedContext}]\n\n${enriched}`;
      contextUsed.push('suggestedContext');
    }

    return {
      enrichedPrompt: enriched,
      contextUsed,
      warnings: contextReport.warnings,
    };
  }

  // ===========================================================================
  // ANALYSE D'ENTR√âE
  // ===========================================================================

  /**
   * Analyser l'entr√©e utilisateur
   * Utilise un mod√®le optimis√© (moins cher) car c'est une t√¢che simple
   */
  private async analyzeInput(input: string): Promise<InputAnalysis> {
    try {
      // Utiliser thinkOptimized pour √©conomiser des tokens - analyse simple
      const response = await this.thinkOptimized(
        `Analyse cette entr√©e utilisateur et r√©ponds en JSON:\n\n"${input}"`,
        'simple_chat' // T√¢che simple, peut utiliser un mod√®le gratuit/cheap
      );

      const jsonMatch = response.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        return JSON.parse(jsonMatch[0]);
      }
    } catch (error) {
      console.error('[Vox] Erreur analyse:', error);
    }

    // Fallback
    return {
      intent: 'other',
      confidence: 0.5,
      needsClarification: false,
      clarificationQuestion: null,
      processedInput: input,
      suggestedPriority: 5,
      emotionalTone: 'neutral',
    };
  }

  // ===========================================================================
  // MESSAGE HANDLERS
  // ===========================================================================

  protected async handleMessage(message: AgentMessage): Promise<void> {
    // Circuit breaker: ignorer si d√©j√† en train de traiter un message
    if (this.isProcessingMessage) {
      console.log(`[Vox] ‚ö†Ô∏è Message ignor√© (d√©j√† en traitement): ${message.type}`);
      return;
    }

    // Ignorer les messages qui ne sont pas destin√©s √† Vox
    if (message.to !== 'vox' && message.to !== 'broadcast') {
      return;
    }

    this.isProcessingMessage = true;
    try {
      switch (message.type) {
        case 'response_ready':
          // Ne traiter que les r√©ponses de Brain, pas les broadcasts pour user
          if (message.from === 'brain') {
            await this.handleBrainResponse(message);
          }
          break;

        case 'context_report':
          this.handleContextReport(message);
          break;

        case 'error':
          await this.handleError(message);
          break;

        default:
          console.log(`[Vox] Message non g√©r√©: ${message.type}`);
      }
    } finally {
      this.isProcessingMessage = false;
    }
  }

  /**
   * G√©rer le rapport de contexte de Memory
   */
  private handleContextReport(message: AgentMessage): void {
    const payload = message.payload as {
      report: ContextReport;
      requestId: string;
    };

    const callback = this.pendingContextRequests.get(payload.requestId);
    if (callback) {
      this.pendingContextRequests.delete(payload.requestId);
      callback(payload.report);
    }
  }

  /**
   * G√©rer la r√©ponse du Brain
   */
  private async handleBrainResponse(message: AgentMessage): Promise<void> {
    const payload = message.payload as {
      response: string;
      confidence: number;
      sources?: string[];
      metadata?: Record<string, unknown>;
    };

    this.state.pendingResponse = false;

    // V√©rifier que la r√©ponse existe
    if (!payload.response) {
      console.error('[Vox] ‚ö†Ô∏è R√©ponse Brain vide ou undefined, utilisation fallback');
      this.emitToUser("D√©sol√©, je n'ai pas pu g√©n√©rer de r√©ponse. Pouvez-vous reformuler ?");
      return;
    }

    // Formater la r√©ponse pour l'utilisateur
    let formattedResponse = payload.response;

    // Ajouter indicateur de confiance si < 80%
    if (payload.confidence < 0.8) {
      formattedResponse += `\n\n_(Confiance: ${Math.round(payload.confidence * 100)}%)_`;
    }

    // Ajouter les sources si pr√©sentes
    if (payload.sources && payload.sources.length > 0) {
      formattedResponse += `\n\n**Sources:** ${payload.sources.join(', ')}`;
    }

    // Ajouter √† l'historique AVANT d'√©mettre
    this.state.conversationHistory.push({
      role: 'assistant',
      content: formattedResponse,
      timestamp: new Date(),
    });

    // IMPORTANT: Stocker en m√©moire AVANT d'√©mettre vers l'utilisateur
    // Cela garantit que le contexte est disponible pour le prochain message
    if (this.state.lastUserMessage) {
      this.send('memory', 'store_conversation', {
        userMessage: this.state.lastUserMessage,
        assistantResponse: payload.response,
        sessionId: this.state.currentSessionId,
      });
      this.state.lastUserMessage = null;
    }

    // √âmettre vers l'utilisateur APR√àS le stockage
    this.emitToUser(formattedResponse);
  }

  /**
   * G√©rer les erreurs
   */
  private async handleError(message: AgentMessage): Promise<void> {
    const error = message.payload as { message: string; recoverable: boolean };

    this.state.currentMood = 'apologetic';
    this.state.pendingResponse = false;

    const apology = error.recoverable
      ? `Je rencontre une difficult√© : ${error.message}. Je r√©essaie...`
      : `D√©sol√©, une erreur s'est produite : ${error.message}. Pouvez-vous reformuler ?`;

    this.emitToUser(apology);
  }

  // ===========================================================================
  // √âMISSION VERS UTILISATEUR
  // ===========================================================================

  /**
   * √âmettre une r√©ponse vers l'utilisateur
   */
  private emitToUser(message: string): void {
    if (!message) {
      console.error('[Vox] ‚ö†Ô∏è Tentative d\'√©mission d\'un message vide ou undefined');
      return;
    }

    // Broadcast vers tous les agents - l'interface CLI √©coute ce message
    // Les autres agents (Memory, Brain) ignorent les messages 'response_ready' avec target: 'user'
    this.send('broadcast', 'response_ready', {
      target: 'user',
      message,
      timestamp: new Date(),
    });

    console.log(`[Vox] üì§ R√©ponse: "${message.substring(0, 100)}..."`);
  }

  // ===========================================================================
  // API PUBLIQUE
  // ===========================================================================

  /**
   * Obtenir le contexte r√©cent de conversation
   */
  private getRecentContext(turns = 10): ConversationTurn[] {
    return this.state.conversationHistory.slice(-turns);
  }

  /**
   * Obtenir l'historique complet
   */
  getConversationHistory(): ConversationTurn[] {
    return [...this.state.conversationHistory];
  }

  /**
   * R√©initialiser la conversation
   */
  resetConversation(): void {
    this.state.conversationHistory = [];
    this.state.currentMood = 'neutral';
    this.state.currentSessionId = this.generateSessionId();
    console.log('[Vox] Conversation r√©initialis√©e');
  }

  /**
   * Obtenir l'ID de session courante
   */
  getSessionId(): string {
    return this.state.currentSessionId;
  }
}
